assignees,body,closed_at,created_at,id,labels,state,title,updated_at,author,repo_name
take-certain-word-end,"```   File ""/home/zug/.local/share/virtualenvs/github2pandas_manager-hrFOyCxn/src/github2pandas/github2pandas/version.py"", line 233, in generate_version_pandas_tables     if not Utility.check_for_updates_paginated(commits, old_commits):   File ""/home/zug/.local/share/virtualenvs/github2pandas_manager-hrFOyCxn/src/github2pandas/github2pandas/utility.py"", line 118, in check_for_updates_paginated     if new_paginated_list.totalCount == 0  ...  Github.GithubException.GithubException: 409 {""message"": ""Git Repository is empty."", ""documentation_url"": ""https://docs.github.com/rest/reference/repos#list-commits""} ```  ",2021-09-13 04:27:54,2021-09-06 09:24:48,988967710.0,,closed,Handling of completly empty repositories,2021-09-13 04:27:55,take-certain-word-end,github2pandas
take-certain-word-end,,,2021-09-01 07:17:45,984795335.0,,open,Embed empty repository in testing methods,2021-09-01 07:17:45,take-certain-word-end,github2pandas
take-certain-word-end,,,2021-08-29 12:37:51,982088445.0,,open,Add repository class to wiki,2021-08-29 12:37:51,take-certain-word-end,github2pandas
take-certain-word-end,"`df.loc[index, 'prog_language'] = repo.language`",2021-09-01 07:17:10,2021-08-19 10:51:03,974533203.0,,closed,Add language extraction to repository class,2021-09-01 07:17:10,take-certain-word-end,github2pandas
take-certain-word-end,Include project overview generation as `Repository` Class,2021-08-31 06:11:42,2021-08-17 11:34:57,972590729.0,,closed,Integrate general repository data aggregation,2021-08-31 06:11:42,take-certain-word-end,github2pandas
love-go-past-name,"author in commits are sometimes None.  Problem: author can not be identified with a github account Solution: keep author name from commit in a new column if author is not defined in github. !!!The author information won't be lost, but are not anonymos anymore!!!  A processing of the data can replace manually authors which don't have an github account. ",2021-05-27 14:47:38,2021-05-27 08:48:33,903420843.0,,closed,Commits resolve author problem,2021-05-27 14:47:38,love-go-past-name,github2pandas
love-go-past-name,Commits which are/will be merged to a other branch,2021-05-27 09:49:16,2021-05-27 08:42:04,903413722.0,,closed,Add get_commits() on a pull request,2021-05-27 09:49:16,love-go-past-name,github2pandas
love-go-past-name,,2021-05-19 06:04:59,2021-05-19 05:19:10,895001440.0,,closed,get mutiple repos with pattern,2021-05-19 06:05:00,love-go-past-name,github2pandas
,"Sys: Win 10, Python 3.9.4, new github token style  Hey again, while using your Version class under Windows 10 the script in your Version_Example Notebook faces a common issue with git2net and multiprocessing under point ""Step 2: Mining Repository via git2net"":  > Found no database on provided path. Starting from scratch. >  > AttributeError                            Traceback (most recent call last) > <ipython-input-5-32bf1f0e8666> in <module> >       8 Version.no_of_proceses = 8 >       9 start_time = time.time() > ---> 10 Version.generate_version_pandas_tables(repo=repo, data_root_dir=default_data_folder) >      11 print(""\nTime: %.3fs"" % (time.time() - start_time)) >  > c:\users\tower\hiwi\github2pandas\github2pandas\version.py in generate_version_pandas_tables(repo, data_root_dir) >     209         """""" >     210  > --> 211         Version.generate_data_base(data_root_dir) >     212  >     213         version_folder = Path(data_root_dir, Version.VERSION_DIR) >  > c:\users\tower\hiwi\github2pandas\github2pandas\version.py in generate_data_base(data_root_dir) >     186             os.remove(sqlite_db_file) >     187  > --> 188         git2net.mine_git_repo(repo_dir, sqlite_db_file, >     189                               extract_complexity=True, >     190                               extract_text=True, >  > c:\users\tower\hiwi\github2pandas\venv\lib\site-packages\git2net\extraction.py in mine_git_repo(git_repo_dir, sqlite_db_file, commits, use_blocks, no_of_processes, chunksize, exclude, blame_C, blame_w, max_modifications, timeout, extract_text, extract_complexity, extract_merges, extract_merge_deletions, all_branches) >    1568  >    1569     if extraction_settings['no_of_processes'] > 1: > -> 1570         _process_repo_parallel(git_repo_dir, sqlite_db_file, u_commits, extraction_settings) >    1571     else: >    1572         _process_repo_serial(git_repo_dir, sqlite_db_file, u_commits, extraction_settings) >  > c:\users\tower\hiwi\github2pandas\venv\lib\site-packages\git2net\extraction.py in _process_repo_parallel(git_repo_dir, sqlite_db_file, commits, extraction_settings) >    1164         git_init_lock = git_init_lock_ >    1165  > -> 1166     with multiprocessing.Pool(extraction_settings['no_of_processes'], >    1167                               initializer=_init, initargs=(git_repo_dir,git_init_lock)) as p: >    1168         with tqdm(total=len(args), desc='Parallel ({0} processes)' \ >  > ~\AppData\Local\Programs\Python\Python39\lib\multiprocessing\context.py in Pool(self, processes, initializer, initargs, maxtasksperchild) >     117         '''Returns a process pool object''' >     118         from .pool import Pool > --> 119         return Pool(processes, initializer, initargs, maxtasksperchild, >     120                     context=self.get_context()) >     121  >  > ~\AppData\Local\Programs\Python\Python39\lib\multiprocessing\pool.py in __init__(self, processes, initializer, initargs, maxtasksperchild, context) >     210         self._processes = processes >     211         try: > --> 212             self._repopulate_pool() >     213         except Exception: >     214             for p in self._pool: >  > ~\AppData\Local\Programs\Python\Python39\lib\multiprocessing\pool.py in _repopulate_pool(self) >     301  >     302     def _repopulate_pool(self): > --> 303         return self._repopulate_pool_static(self._ctx, self.Process, >     304                                             self._processes, >     305                                             self._pool, self._inqueue, >  > ~\AppData\Local\Programs\Python\Python39\lib\multiprocessing\pool.py in _repopulate_pool_static(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception) >     324             w.name = w.name.replace('Process', 'PoolWorker') >     325             w.daemon = True > --> 326             w.start() >     327             pool.append(w) >     328             util.debug('added worker') >  > ~\AppData\Local\Programs\Python\Python39\lib\multiprocessing\process.py in start(self) >     119                'daemonic processes are not allowed to have children' >     120         _cleanup() > --> 121         self._popen = self._Popen(self) >     122         self._sentinel = self._popen.sentinel >     123         # Avoid a refcycle if the target function holds an indirect >  > ~\AppData\Local\Programs\Python\Python39\lib\multiprocessing\context.py in _Popen(process_obj) >     325         def _Popen(process_obj): >     326             from .popen_spawn_win32 import Popen > --> 327             return Popen(process_obj) >     328  >     329     class SpawnContext(BaseContext): >  > ~\AppData\Local\Programs\Python\Python39\lib\multiprocessing\popen_spawn_win32.py in __init__(self, process_obj) >      91             try: >      92                 reduction.dump(prep_data, to_child) > ---> 93                 reduction.dump(process_obj, to_child) >      94             finally: >      95                 set_spawning_popen(None) >  > ~\AppData\Local\Programs\Python\Python39\lib\multiprocessing\reduction.py in dump(obj, file, protocol) >      58 def dump(obj, file, protocol=None): >      59     '''Replacement for pickle.dump() using ForkingPickler.''' > ---> 60     ForkingPickler(file, protocol).dump(obj) >      61  >      62 # >  > AttributeError: Can't pickle local object '_process_repo_parallel.<locals>._init'  Weird is one of the first lines of error message: `Version.no_of_proceses = 8` You did definitly set it to 1, not sure why this happens in the background atm. Do you have a clue why this happens? It should/could be a git2net problem tho",2021-04-26 12:06:24,2021-04-26 12:01:05,867626378.0,bug,closed,Win 10 multiprocessing issue with git2net,2021-04-26 12:06:25,set-meet-private-book,github2pandas
,"My System: Python 3.9.4, Windows 10 x64, using the ""new"" github token (style)  Hey, the functions you declared inside the GitRelease() class (git_releases.py) won't write the pandas datagrams to harddrive on Windows 10. I was wondering about the fact, that your Git_Releases_Example Jupyter Notebook won't output a pandas Datagram, but after I tried to use the functions to aggregate git commits/releases I faced the problem, that there was no output and the pandas datagram were empty while debugging. ` GitReleases.generate_git_releases_pandas_tables(repo, default_data_folder) git_releases = GitReleases.get_git_releases(default_data_folder) ` git_releases is empty after running through this line of code. After I downloaded the github2pandas package via pip / pipenv and used it inside my own code the execution is way to fast. As far as I have understood the functions should at least download the git repository you are trying to analyse. But there is no temporary folder with the git repo. Only the Repo.json file gets written inside the data folder.  I'm pretty sure the github repos I tried to analyse are valid and I can connect to them. There is no exception raised while using your functions.  I guess that is not intentional, cause in the wiki the pandas datagram output files are already explained. Can you fix this? Tell me what I need to provide, if you need more infos to solve this crime x)",2021-05-03 09:22:56,2021-04-25 21:32:04,867119304.0,,closed,GitReleases class functions won't write pandas datagrams,2021-05-03 12:33:12,set-meet-private-book,github2pandas
,,,2021-04-12 13:54:56,856003824.0,,open,Implement logging concept,2021-04-12 13:54:56,take-certain-word-end,github2pandas
take-certain-word-end,... after publication of the package,2021-07-04 09:33:53,2021-04-12 13:53:37,856002535.0,,closed,Integrate CoLab or Binder References,2021-07-04 09:33:53,take-certain-word-end,github2pandas
,folder with test data will remain. Clean up after tests,2021-04-12 08:41:39,2021-04-08 04:37:16,853050456.0,,closed,delete Test folder automatically,2021-04-12 08:41:39,love-go-past-name,github2pandas
love-go-past-name,Check Project for:  - [x] Naming Convention - [x] correct documentation - [x] tests (add some more?) - [x] Check Examples,2021-04-07 06:45:30,2021-03-31 09:32:16,846285942.0,,closed,Check whole project,2021-04-07 06:45:30,love-go-past-name,github2pandas
love-go-past-name,add new extraction,2021-03-31 09:19:45,2021-03-31 08:00:05,846133002.0,enhancement,closed,extract git releases,2021-03-31 09:19:45,love-go-past-name,github2pandas
take-certain-word-end,"I get an AttributeError in Version_Example.ipynb.  Running the Version with 4 processes  --------------------------------------------------------------------------- ``` AttributeError                            Traceback (most recent call last) <ipython-input-5-58164beaaa3a> in <module>       8 Version.no_of_proceses = 4       9 start_time = time.time() ---> 10 Version.generate_version_pandas_tables(data_root_dir=default_data_folder)      11 print(""\nTime: %.3fs"" % (time.time() - start_time))  ...\github2pandas\version.py in generate_version_pandas_tables(data_root_dir)     197         """"""     198  --> 199         Version.generate_data_base(data_root_dir)     200      201         version_folder = Path(data_root_dir, Version.VERSION_DIR)  ...\github2pandas\version.py in generate_data_base(data_root_dir)     172             os.remove(sqlite_db_file)     173  --> 174         git2net.mine_git_repo(repo_dir, sqlite_db_file,     175                               extract_complexity=True,     176                               extract_text=True,  ~...\git2net\extraction.py in mine_git_repo(git_repo_dir, sqlite_db_file, commits, use_blocks, no_of_processes, chunksize, exclude, blame_C, blame_w, max_modifications, timeout, extract_text, extract_complexity, extract_merges, extract_merge_deletions, all_branches)    1568     1569     if extraction_settings['no_of_processes'] > 1: -> 1570         _process_repo_parallel(git_repo_dir, sqlite_db_file, u_commits, extraction_settings)    1571     else:    1572         _process_repo_serial(git_repo_dir, sqlite_db_file, u_commits, extraction_settings)  ~...\git2net\extraction.py in _process_repo_parallel(git_repo_dir, sqlite_db_file, commits, extraction_settings)    1164         git_init_lock = git_init_lock_    1165  -> 1166     with multiprocessing.Pool(extraction_settings['no_of_processes'],    1167                               initializer=_init, initargs=(git_repo_dir,git_init_lock)) as p:    1168         with tqdm(total=len(args), desc='Parallel ({0} processes)' \  ...\python38\lib\multiprocessing\context.py in Pool(self, processes, initializer, initargs, maxtasksperchild)     117         '''Returns a process pool object'''     118         from .pool import Pool --> 119         return Pool(processes, initializer, initargs, maxtasksperchild,     120                     context=self.get_context())     121   ...\python38\lib\multiprocessing\pool.py in __init__(self, processes, initializer, initargs, maxtasksperchild, context)     210         self._processes = processes     211         try: --> 212             self._repopulate_pool()     213         except Exception:     214             for p in self._pool:  ...\python38\lib\multiprocessing\pool.py in _repopulate_pool(self)     301      302     def _repopulate_pool(self): --> 303         return self._repopulate_pool_static(self._ctx, self.Process,     304                                             self._processes,     305                                             self._pool, self._inqueue,  ...\python38\lib\multiprocessing\pool.py in _repopulate_pool_static(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)     324             w.name = w.name.replace('Process', 'PoolWorker')     325             w.daemon = True --> 326             w.start()     327             pool.append(w)     328             util.debug('added worker')  ...\python38\lib\multiprocessing\process.py in start(self)     119                'daemonic processes are not allowed to have children'     120         _cleanup() --> 121         self._popen = self._Popen(self)     122         self._sentinel = self._popen.sentinel     123         # Avoid a refcycle if the target function holds an indirect  ...\python38\lib\multiprocessing\context.py in _Popen(process_obj)     325         def _Popen(process_obj):     326             from .popen_spawn_win32 import Popen --> 327             return Popen(process_obj)     328      329     class SpawnContext(BaseContext):  ...\python38\lib\multiprocessing\popen_spawn_win32.py in __init__(self, process_obj)      91             try:      92                 reduction.dump(prep_data, to_child) ---> 93                 reduction.dump(process_obj, to_child)      94             finally:      95                 set_spawning_popen(None)  ...\python38\lib\multiprocessing\reduction.py in dump(obj, file, protocol)      58 def dump(obj, file, protocol=None):      59     '''Replacement for pickle.dump() using ForkingPickler.''' ---> 60     ForkingPickler(file, protocol).dump(obj)      61       62 #  AttributeError: Can't pickle local object '_process_repo_parallel.<locals>._init' ```",2021-04-06 13:05:15,2021-03-26 10:31:59,841807800.0,,closed,AttributeError: Version_Example,2021-04-06 13:05:15,love-go-past-name,github2pandas
,,2021-03-26 05:25:29,2021-03-22 09:10:34,837497983.0,,closed,speed up the aggregation,2021-03-26 05:25:29,love-go-past-name,github2pandas
love-go-past-name,resolve test issues,2021-03-15 10:11:44,2021-03-15 09:02:40,831589201.0,,closed,Tests failing,2021-03-15 10:11:44,love-go-past-name,github2pandas
love-go-past-name,"In the notebook example, despite the unique assignment, 3 instead of 2 developers of the project still appear.   [Workflow_Example.ipynb](https://github.com/TUBAF-IFI-DiPiT/Extract_Git_Activities/blob/main/notebooks/Workflow_Example.ipynb)  Both approaches ```python pd_workflow.commit_author.unique() # Read out the commit name directly pd_workflow.author.unique() # UUID generated by utility function ``` return 3 authors each. How can we filter the ambiguous naming accordingly?",2021-03-26 13:29:33,2021-03-14 12:49:41,831148430.0,,closed,Unique user names,2021-03-26 13:29:33,take-certain-word-end,github2pandas
love-go-past-name,create some models for pandas tables,2021-03-18 08:51:31,2021-03-12 08:27:08,829875939.0,,closed,predefine the pandas tables,2021-03-18 08:51:31,love-go-past-name,github2pandas
love-go-past-name,user data should be saved in a different file and just be referenced by an id,2021-03-12 08:25:21,2021-03-11 12:15:32,829096813.0,,closed,extraction of user data,2021-03-12 08:25:21,love-go-past-name,github2pandas
,Jupyter notebooks for illustrating the basic usage would be helpful for potential users.,2021-03-05 09:00:16,2021-03-05 06:30:09,822791418.0,,closed,Integrate notebook examples,2021-03-05 09:00:16,take-certain-word-end,github2pandas
love-go-past-name,,2021-03-09 07:38:04,2021-03-04 07:00:31,821825890.0,,closed,Aggregate PullRequests,2021-03-09 07:38:04,love-go-past-name,github2pandas
take-certain-word-end&love-go-past-name,,2021-04-29 05:35:07,2021-03-04 06:50:53,821819189.0,,closed,Include documentation infrastructure,2021-04-29 05:35:07,take-certain-word-end,github2pandas
take-certain-word-end,,2021-03-13 10:57:11,2021-03-03 18:42:24,821382882.0,,closed,Integrate workflow analysis,2021-03-13 10:57:11,take-certain-word-end,github2pandas
take-certain-word-end&love-go-past-name,,2021-03-26 13:29:33,2021-03-01 12:33:48,818822668.0,,closed,feature/restructure-project,2021-03-26 13:29:33,love-go-past-name,github2pandas
love-go-past-name,,2021-03-03 13:33:16,2021-03-01 09:50:05,818689008.0,,closed,Extract Issues,2021-03-03 13:33:16,love-go-past-name,github2pandas
take-certain-word-end,,2021-03-03 18:42:07,2021-02-25 13:09:04,816421458.0,,closed,Extract Commit History,2021-03-03 18:42:07,take-certain-word-end,github2pandas
buy-sure-room-art,,2021-11-04 06:45:07,2021-10-13 13:08:34,1025230198.0,,closed,Complete documentation,2021-11-04 06:45:07,take-certain-word-end,github2pandas_manager
,,,2021-09-11 05:49:59,993757680.0,,open,Generate setup.py,2021-09-11 05:49:59,take-certain-word-end,github2pandas_manager
take-certain-word-end,- [ ]  config_parser.py - [ ]  data_extractor.py - [ ]  repository_handler.py - [ ]  start_aggregation.py - [ ]  utilities.py,,2021-08-29 13:10:28,982095502.0,,open,Insert documentation,2021-08-29 13:10:28,take-certain-word-end,github2pandas_manager
buy-sure-room-art,Please transfer the solution from the existing crawler project to the reimplementation.  https://github.com/TUBAF-IFI-DiPiT/github2pandas_manager/blob/4f8d1737918e05db46e0c0ed4473cdda2706c4ee/src/repository_handler.py#L209,2021-10-13 13:06:20,2021-08-29 13:08:52,982095129.0,,closed,Integrate solution for repository lists greater than 1000,2021-10-13 13:06:20,take-certain-word-end,github2pandas_manager
expect-bring-medical-lot,"Aggregation functions are still incomplete  https://github.com/TUBAF-IFI-DiPiT/github2pandas_manager/blob/4f8d1737918e05db46e0c0ed4473cdda2706c4ee/src/data_extractor.py#L41  - [x] `aggPullRequests(repo, repo_base_folder, github_token=None)` - [x] `aggWorkflows(repo, repo_base_folder, github_token=None)` - [x] `aggGitReleases(repo, repo_base_folder, github_token=None)`",2021-10-19 09:19:17,2021-08-29 13:05:30,982094403.0,,closed,Add aggregation function for remaining content,2021-10-19 09:19:17,take-certain-word-end,github2pandas_manager
take-certain-word-end,"- [x]  Name Patterns - [x]  Names  - [x]  Organizations - [x]  Queries (programming language, stars, ...)",2021-08-31 09:44:47,2021-08-29 07:02:46,982013976.0,,closed,Implement repository extraction for different types of requests,2021-08-31 09:44:47,take-certain-word-end,github2pandas_manager
